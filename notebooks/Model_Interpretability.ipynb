{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\habteyes.asfaw\\10Accadamy\\EthioMart_Telegram_NER\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import lime\n",
    "import lime.lime_text\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the fine-tuned NER model and tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare NER model for prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERModel:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def predict(self, texts):\n",
    "        inputs = self.tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        outputs = self.model(**inputs)\n",
    "        predictions = torch.argmax(outputs.logits, dim=2)\n",
    "        return predictions.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize LIME Explainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_lime_explainer(class_names):\n",
    "    return lime.lime_text.LimeTextExplainer(class_names=class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain a single instance using LIME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_instance(text, model_predict, explainer):\n",
    "    exp = explainer.explain_instance(text, model_predict, num_features=10)\n",
    "    return exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize LIME explanation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_lime_explanation(explanation, sample_text):\n",
    "    word_idx = explanation.local_pred[0]\n",
    "    exp_map = explanation.as_map()\n",
    "    labels = list(exp_map.keys())\n",
    "    weights = [exp_map[label] for label in labels]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.barh(labels, weights, color='skyblue')\n",
    "    plt.title(f'LIME Explanation for: \"{sample_text}\"')\n",
    "    plt.xlabel('Weight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate SHAP explanations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_explanation(model, tokenizer, texts):\n",
    "    explainer = shap.Explainer(model, tokenizer)\n",
    "    shap_values = explainer(texts)\n",
    "    return shap_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize SHAP values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_shap_values(shap_values):\n",
    "    shap.initjs()\n",
    "    shap.plots.text(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify difficult cases based on custom logic\n",
    "def analyze_difficult_cases(texts, keyword):\n",
    "    return [text for text in texts if keyword in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Execution Flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model_name = \"your_model_name\"  # Replace with your trained model name\n",
    "    dataset_name = \"your_dataset_name\"  # Replace with your dataset name\n",
    "    class_names = ['O', 'B-Product', 'I-Product', 'B-LOC', 'I-LOC', 'B-Price', 'I-Price']\n",
    "\n",
    "    # Load model and dataset\n",
    "    model, tokenizer = load_model_and_tokenizer(model_name)\n",
    "    dataset = load_dataset(dataset_name, split='validation')\n",
    "    texts = dataset['tokens']  # Assuming your dataset has a 'tokens' field\n",
    "\n",
    "    # Initialize NER model and LIME explainer\n",
    "    ner_model = NERModel(model, tokenizer)\n",
    "    explainer = initialize_lime_explainer(class_names)\n",
    "\n",
    "    # Explain a sample instance\n",
    "    sample_text = texts[0]  # Change index for different samples\n",
    "    explanation = explain_instance(sample_text, ner_model.predict, explainer)\n",
    "\n",
    "    # Visualize LIME explanation\n",
    "    visualize_lime_explanation(explanation, sample_text)\n",
    "\n",
    "    # SHAP analysis for a batch of texts\n",
    "    shap_values = shap_explanation(model, tokenizer, texts[:10])  # Analyze first 10 texts\n",
    "\n",
    "    # Visualize SHAP values for the first text\n",
    "    visualize_shap_values(shap_values)\n",
    "\n",
    "    # Analyze difficult cases\n",
    "    difficult_texts = analyze_difficult_cases(texts, \"ambiguous\")  # Customize keyword as needed\n",
    "\n",
    "    # Generate and print a report on model decision-making\n",
    "    report = {\n",
    "        \"num_difficult_cases\": len(difficult_texts),\n",
    "        \"examples\": difficult_texts\n",
    "    }\n",
    "\n",
    "    print(\"Model Decision-Making Report:\")\n",
    "    print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
